\documentclass{article}
\title{Notes on network/generation interval}
\author{Sang Woo Park}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}

\usepackage{hyperref}
\usepackage{natbib}
\usepackage{hyperref}
\bibliographystyle{chicago}
\date{\today}

\usepackage{xspace}
\newcommand*{\ie}{i.e.\@\xspace}

\newcommand{\Ro}{\mathcal{R}_0}
\newcommand{\Rr}{\mathcal{R}}
\newcommand{\tsub}[2]{#1_{{\textrm{\tiny #2}}}}

\begin{document}
\maketitle

\section{Censored generation interval distributions}

Following \cite{champredon2015intrinsic}, we can write the number of infection occuring at time $t$ caused by infectors who were themselves infected at time $s$ as
\begin{equation}
i_s(t) = K(t-s) i(s) S(t)
\end{equation}
Writing the kernel as the product of the intrinsic genreation distributions and $\Ro$, we get
\begin{equation}
i_s(t) = \Ro g(t-s) i(s) S(t)
\end{equation}

The censored generation interval distributions is what is often measured and we have to account for all infections that happen before time $t$.
Note that number of infection occuring at time $s$ caused by infectors who were themselves infected at time $s-\tau$ is given by 
\begin{equation}
i_{s-\tau}(s) = \Ro i(s-\tau) g(\tau) S(s)
\end{equation}
Normalizing this gives the backward generation interval distributions of the cohorts at time $s$ but we are interested in all infections that are $\tau$ time steps apart before time $t$:
\begin{equation}
\Ro \int_\tau^t i(s-\tau) g(\tau) S(s) ds.
\end{equation}
Then, the censored generation interval is given by
\begin{equation}
c_t(\tau)= \frac{\int_\tau^t i(s-\tau) g(\tau) S(s) ds}{\int_0^t \int_x^t i(s-x) g(x) S(s) ds dx}.
\end{equation}
We note that the denominater is basically cumulative incidence up to time $t$ divided by $\Ro$. The stragihtforward intuition behind this is that we are normalizing by all incidence before time $t$. Mathematically, we have the following:
\begin{equation}
\begin{aligned}
\Ro \int_0^t \int_x^t i(s-x) g(x) S(s) ds dx &= \int_0^t \Ro S(s) \int_0^s i(s-x) g(x)  dx ds\\
&= \int_0^t i(s) ds
\end{aligned}
\end{equation}
Then,
\begin{equation}
c_t(\tau) = \frac{\Ro \int_{\tau}^t i(s-\tau) S(s) ds}{\int_0^t i(s) ds} g(\tau)
\end{equation}

We are going to come back to these later. Rather we want to focus on temporal correction first.

\section{Temporal correction}

During an exponential growth period, censored generation interval can be written as follows:
\begin{equation}
\tsub{g}{obs}(\tau) = \Rr g(\tau) \exp(-r\tau),
\end{equation}
This is generation interval distributions we expect to observe during an early outbreak (growing at rate $r$).
Hence, to recover the intrinsic generation interval distributions, we can take the weighted distribution of the observed distribution:
\begin{equation}
g(\tau) = \frac{1}{\Rr} \tsub{g}{obs}(\tau) \exp(r\tau).
\end{equation}
Furthermore, $\Rr$ should be estimated by
\begin{equation}
\Rr = \int_0^\infty \tsub{g}{obs}(\tau) \exp(r\tau) d\tau
\end{equation}
This contrasts with the well-known Euler-Lotka equation:
\begin{equation}
\Rr = 1\left/\int_0^\infty g(\tau) \exp(-r\tau) d\tau\right.
\end{equation}
Using this equation will lead to underestimation of $\Rr$ as well as mean generation interval (I think we can prove this using weighted AM-HM ineqaulity).

\subsection{Numerical analysis}

Consider the Ebola epidemic. 


\subsection{Simulation study - deterministic framework}

We simulate an epidemic with Ebola parameters assuming $\Rr = 2$ with a population size of 60000. We study the epidemic when daily cases range between 20 and 200. For simplicity, we do not assume any under-reportings.
Little $r$ is estimated by fitting an exponential curve with negative binomial error through maximum likelihood.
Confidence interval is constructed using normal approximation.
Confidence interval for mean generation interval and $\Rr$ is constructed by bootstrapping sample of generation intervals and drawing a random value for $r$ from normal distribution using its estimated mean and standard error from MLE.

First, we can look at the estimates:

\includegraphics[width=\textwidth]{../fig/estimate.pdf}

Everything is underestimated. It seems to be driven by underestimation of little $r$ but I'm not sure why (and this is probably affecting coverage). Maybe we want to simulate the epidemic longer? We can see that uncorrected estimates yield much lower mean generation interval (gen) and $\Rr$. Let's look at the coverage:

\includegraphics[width=\textwidth]{../fig/coverage.pdf}

Coverage also sucks. I used to get higher coverage when I was being less careful... I don't think it's possible to get nominal coverage using a deterministic framework (see \cite{king2015avoidable}). I was wondering whether underestimation of little $r$ (and hence its coverage) affects other estimates. So I tried taking simulations where true little $r$ is covered by confidence interval.

\includegraphics[width=\textwidth]{../fig/coverage2.pdf}

$\Rr$ coverage increases but mean generation interval coverage seems to stay the same. We need to think of a more statistically robust method that somehow accounts for process error and is simple. I want to stick with the intuition...





\bibliography{network}
\end{document}
